# ğŸ§  Sentiment Analysis with Word2Vec & RNNs + DCGAN on PathMNIST

This repository implements two advanced deep learning tasks:

1. **Sentiment classification** on the IMDB movie review dataset using Word2Vec and RNN-based architectures (RNN, LSTM, GRU, BiLSTM).
2. **Image generation** on the PathMNIST dataset using a **Deep Convolutional GAN (DCGAN)**.

> ğŸ” Focus: Sequence modeling with word embeddings and time series networks + GAN-based synthetic data generation and evaluation via FID score.

---

## ğŸ› ï¸ Tech Stack

* Python 3.10
* TensorFlow/Keras (for NLP models)
* PyTorch (for GANs)
* Gensim Word2Vec
* MedMNIST (PathMNIST dataset)
* Scikit-learn, Matplotlib, Seaborn

---

## âœ… Part 1: IMDB Sentiment Classification using Word2Vec + RNN Variants

### ğŸ“¦ Dataset

* Kaggle IMDB dataset: 50,000 labeled reviews
* Preprocessing:

  * HTML stripping, lowercase conversion
  * Tokenization + Stopword removal
  * Lemmatization + contraction expansion

### ğŸ§  Embedding

* Used **Gensim-trained Word2Vec (CBOW)** model on training tokens
* Created embedding matrix for Keras Embedding layer

### ğŸ§ª Models Trained:

#### ğŸ”¹ Simple RNN

* Architecture: Embedding â†’ SimpleRNN(128) â†’ Dense(1, sigmoid)
* EarlyStopping (patience=8)
* â›” Weakest performance overall
* ğŸ“Š Accuracy: 68.08%, F1: 65.44%

#### ğŸ”¹ LSTM

* Architecture: Embedding â†’ LSTM(128, dropout=0.2) â†’ Dense(1, sigmoid)
* ğŸ† Strong recall performance: **Recall = 88.96%**, F1 = 87.07%
* Accuracy: 86.79%

#### ğŸ”¹ GRU

* Architecture: Embedding â†’ GRU(128, dropout=0.2) â†’ Dense(1, sigmoid)
* ğŸ“Œ Precision-focused: **Precision = 88.88%**, F1 = 86.33%
* Accuracy: 86.71%

#### ğŸ”¹ BiLSTM

* Architecture: Embedding â†’ Bidirectional(LSTM(128, dropout=0.2)) â†’ Dense(1, sigmoid)
* âœ… Best overall: Accuracy = 86.95%, F1 Score = **86.97%**
* Balanced precision and recall

### ğŸ“Š Final Results Table

| Model  | Accuracy | Precision | Recall | F1 Score     |
| ------ | -------- | --------- | ------ | ------------ |
| RNN    | 68.08%   | 71.34%    | 60.44% | 65.44%       |
| LSTM   | 86.79%   | 85.26%    | 88.96% | 87.07%       |
| GRU    | 86.71%   | 88.88%    | 83.92% | 86.33%       |
| BiLSTM | 86.95%   | 86.84%    | 87.10% | **86.97%** âœ… |

---

## âœ… Part 2: DCGAN for Medical Image Synthesis (PathMNIST)

### ğŸ©º Dataset

* **PathMNIST** from MedMNIST: 28x28 RGB microscopy tissue patches
* Split: Train/Test
* Transformed using normalization: \[-1, 1]

### ğŸ¯ DCGAN Setup

* **Generator**:

  * Linear(z\_dim â†’ 1024Ã—4Ã—4) â†’ ConvTranspose2D blocks
  * Hidden Layers: 1024 â†’ 512 â†’ 256 â†’ 128 â†’ 3 (RGB)
  * Activation: ReLU (hidden), Tanh (output)

* **Discriminator**:

  * 5 Conv2D layers + LeakyReLU(0.2) + BatchNorm
  * Output: Fully connected layer with BCEWithLogitsLoss

### ğŸ§ª Training

* Optimizer: Adam (lr = 0.0002, betas=(0.5, 0.999))
* Epochs: 1000 (early stopping at epoch **56**)
* Loss Curves: Generator loss increased as Discriminator stabilized
* No evidence of mode collapse

### ğŸ“ˆ FID Score Evaluation

* Generated 1000 fake + 1000 real images
* Calculated **FrÃ©chet Inception Distance (FID)** using `pytorch-fid`
* ğŸ“Š **FID Score: 102.12**

### ğŸ–¼ï¸ Visual Inspection

* Generated images (n=32) show texture/color diversity
* Gradual improvement in visual quality over epochs
* Generator converged smoothly

---

## ğŸ“ˆ Summary Tables

### Sentiment Classification (IMDB)

* Word2Vec + RNN Variants
* BiLSTM delivered highest F1 and best balance

### GAN (PathMNIST)

* DCGAN with 5-layer discriminator, 4-layer generator
* FID score used for evaluation (no collapse detected)

---

## ğŸ·ï¸ Tags

`Sentiment Analysis` `IMDB Dataset` `Word2Vec` `RNN` `LSTM` `GRU` `BiLSTM`
`GAN` `DCGAN` `FID` `PyTorch` `TensorFlow` `Keras` `PathMNIST` `MedMNIST` `Deep Learning Projects`
